{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/dh1/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Non-parametric\n",
    "Entropy based MNIST Classifier \n",
    "Stage1 : saving MNIST Traing data entropy\n",
    "\"\"\"\n",
    "import torch \n",
    "import torchvision \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time \n",
    "import pickle \n",
    "import random\n",
    "import numpy as np \n",
    "import argparse\n",
    "from tqdm import tqdm \n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTWarpper(Dataset):\n",
    "    def __init__(self, root, train, transform):\n",
    "        self.data = torchvision.datasets.MNIST(root=root, train=train, transform=transform)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        return self.data[x]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def compute_entropy(digit_image):\n",
    "    assert digit_image.size() == (1, 1, 28,28) \n",
    "    digit_image = digit_image.flatten()\n",
    "    digit_image = digit_image / digit_image.sum() #[Role]:???\n",
    "    assert abs(digit_image.sum() - 1.0) < 1e-5, digit_image.sum() #[Role]:???\n",
    "    entropy =  (- digit_image * torch.nan_to_num(digit_image.log())).sum() # \\sum - p log p\n",
    "    assert entropy >=0\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "flags = easydict.EasyDict({\n",
    "        'data_path': 'untracked',        \n",
    "        'config': 'config.yaml', \n",
    "        'post_fix': '', \n",
    "        'seed': 0, \n",
    "        'no_date': True, \n",
    "        'date': 2023_02_06-15_02_06,\n",
    "        'save_dir': 'results/seed-0',\n",
    "        'start_time': 1675670579.9275126,\n",
    "        'exp_path': 'results/seed-0',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==== üîñ Argument Setting ====\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--exp-path\") #[Role]:???\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# flags = OmegaConf.load(f\"{args.exp_path}/config.yaml\")\n",
    "# for key in vars(args):\n",
    "#     setattr(flags, key, getattr(args, key))\n",
    "\n",
    "# random.seed(flags.seed)\n",
    "# np.random.seed(flags.seed)\n",
    "# torch.manual_seed(flags.seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# flags.start_time = time.time()\n",
    "# OmegaConf.save(flags, f'{flags.save_dir}/config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# ==== üîñ Running the Experiment ====\n",
    "CLS_ENTROPY = pickle.load(open(f\"{flags.exp_path}/cls_entropy.pkl\", mode='rb'))\n",
    "CLS_MEAN = CLS_ENTROPY.mean(dim=1)\n",
    "\n",
    "test_dataset = MNISTWarpper(flags.data_path, train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "pbar = tqdm(enumerate(test_loader))\n",
    "Y = []\n",
    "Y_HAT = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0870, 4.2729, 4.9438, 4.9019, 4.7628, 4.8219, 4.8648, 4.6918, 4.9676,\n",
       "        4.7713])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2426)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eq = 0  #[Role]:???\n",
    "for i,(x,y) in pbar:\n",
    "    entropy = compute_entropy(x)\n",
    "    y_hat = torch.argmin((CLS_MEAN-entropy).abs()) #[Role]:???\n",
    "    Y.append(y.squeeze().item()) \n",
    "    Y_HAT.append(y_hat.item())\n",
    "    eq += (y.squeeze()== y_hat).sum() #[Role]:???\n",
    "    # duration = time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-flags.start_time))\n",
    "    # pbar.set_description(f\"[INFO]üß™{__file__}|üçÄ{flags.save_dir}|‚åõÔ∏èN:({i:.2E}) P:({i / len(test_dataset)*100:.2f}%) D:({duration})| accuracy: {eq/(i+1)}:.2f\")\n",
    "\n",
    "print(eq)\n",
    "\n",
    "# # post process for saving Y and Y_HAT as tensor\n",
    "\n",
    "# Y = torch.tensor(Y)\n",
    "# Y_HAT = torch.tensor(Y_HAT)\n",
    "\n",
    "# print(f\"[INFO] '{flags.save_dir}/Y.pkl' tensor size: {Y.size()}\")\n",
    "# print(f\"[INFO] '{flags.save_dir}/Y_HAT.pkl' tensor size: {Y_HAT.size()}\")\n",
    "\n",
    "# # Savae the result \n",
    "# with open(f'{flags.save_dir}/Y_HAT.pkl', 'wb') as f:\n",
    "#     print(f\"[INFO] saved '{flags.save_dir}/Y_HAT.pkl'\")\n",
    "#     pickle.dump(Y_HAT, f)\n",
    "\n",
    "# with open(f'{flags.save_dir}/Y.pkl', 'wb') as f:\n",
    "#     print(f\"[INFO] saved '{flags.save_dir}/Y.pkl'\")\n",
    "#     pickle.dump(Y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b036c47a88b6801bd1214d95b23982f260fad58004fa31cc4ee261405de95658"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
