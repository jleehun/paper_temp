{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhlee/anaconda3/envs/dh1/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Non-parametric\n",
    "Entropy based MNIST Classifier \n",
    "Stage1 : saving MNIST Traing data entropy\n",
    "\"\"\"\n",
    "import torch \n",
    "import torchvision #[Role]:???\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import pickle \n",
    "import random\n",
    "import numpy as np \n",
    "import argparse\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "from distutils.util import strtobool\n",
    "from omegaconf import OmegaConf\n",
    "import easydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTWarpper(Dataset):\n",
    "    def __init__(self, root, train, transform):\n",
    "        self.data = torchvision.datasets.MNIST(root=root, train=train, transform=transform, download=True)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        return self.data[x]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def compute_entropy(digit_image):\n",
    "    assert digit_image.size() == (1, 1, 28,28)\n",
    "    digit_image = digit_image.flatten()\n",
    "    digit_image = digit_image / digit_image.sum() #[Role]:???\n",
    "    assert abs(digit_image.sum() - 1.0) < 1e-5, digit_image.sum() #[Role]:???\n",
    "    entropy =  (- digit_image * torch.nan_to_num(digit_image.log())).sum() # \\sum - p log p \n",
    "    assert entropy >=0\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': 'untracked', 'config': 'config.yaml', 'post_fix': '', 'seed': 0, 'no_date': True, 'date': '2023_02_06-15_14_49', 'save_dir': 'results/seed-0', 'start_time': 1675664089.478833}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "args = easydict.EasyDict({\n",
    "        'data_path': 'untracked',        \n",
    "        'config': 'config.yaml', \n",
    "        'post_fix': '', \n",
    "        'seed': 0, \n",
    "        'no_date': True, \n",
    " \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_path': 'untracked', 'config': 'config.yaml', 'post_fix': '', 'seed': 0, 'no_date': True, 'date': '2023_02_06-15_14_49', 'save_dir': 'results/seed-0', 'start_time': 1675664089.478833}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "flags = OmegaConf.load('./config.yaml')\n",
    "for key in vars(args):\n",
    "    setattr(flags, key, getattr(args, key))\n",
    "\n",
    "random.seed(flags.seed)\n",
    "np.random.seed(flags.seed)\n",
    "torch.manual_seed(flags.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "flags.date = datetime.datetime.now().strftime(format=\"%Y_%m_%d-%H_%M_%S\")\n",
    "flags.save_dir = f\"results/seed-{flags.seed}\"\n",
    "if not flags.no_date: #[Role]:???\n",
    "    flags.save_dir = flags.save_dir + f\"-{flags.date}\"\n",
    "flags.start_time = time.time()\n",
    "\n",
    "print(flags) \n",
    "\n",
    "# if not os.path.exists(flags.save_dir):\n",
    "#     os.makedirs(flags.save_dir)\n",
    "# OmegaConf.save(flags, f'{flags.save_dir}/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [00:20, 2994.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  10\n",
      "1 :  10\n",
      "2 :  10\n",
      "3 :  10\n",
      "4 :  10\n",
      "5 :  10\n",
      "6 :  10\n",
      "7 :  10\n",
      "8 :  10\n",
      "9 :  10\n",
      "[INFO] 0-th class 5923 --> 5421\n",
      "[INFO] 1-th class 6742 --> 5421\n",
      "[INFO] 2-th class 5958 --> 5421\n",
      "[INFO] 3-th class 6131 --> 5421\n",
      "[INFO] 4-th class 5842 --> 5421\n",
      "[INFO] 5-th class 5421 --> 5421\n",
      "[INFO] 6-th class 5918 --> 5421\n",
      "[INFO] 7-th class 6265 --> 5421\n",
      "[INFO] 8-th class 5851 --> 5421\n",
      "[INFO] 9-th class 5949 --> 5421\n"
     ]
    }
   ],
   "source": [
    "# ==== 🔖 Running the Experiment ====\n",
    "CLS_ENTROPY = [[] for i in range(10)] # holder for the entropy for class samples\n",
    "SAMPLE_INDEX = [[] for i in range(10)] #[Role]:???\n",
    "\n",
    "train_dataset = MNISTWarpper(flags.data_path, train=True, transform=torchvision.transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=1) #[Role]:???\n",
    "pbar = tqdm(enumerate(train_loader))\n",
    "for i,(x,y) in pbar:\n",
    "    entropy = compute_entropy(x) #[Role]:???\n",
    "    CLS_ENTROPY[y.item()].append(compute_entropy(x))\n",
    "    SAMPLE_INDEX[y.item()].append(i)\n",
    "    # duration = time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-flags.start_time))\n",
    "    # pbar.set_description(f\"[INFO]🧪{__file__}|🍀{flags.save_dir}|⌛️N:({i:.2E}) P:({i / len(train_dataset)*100:.2f}%) D:({duration})|\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'{i} :  {len(CLS_ENTROPY[i])}')\n",
    "\n",
    "# post process for saving CLS as tensor\n",
    "MIN_SIZE = min([len(CLS_ENTROPY[i]) for i in range(10)]) #[Role]:???\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"[INFO] {i}-th class {len(CLS_ENTROPY[i])} --> {MIN_SIZE}\")\n",
    "    CLS_ENTROPY[i] = torch.tensor(CLS_ENTROPY[i][:MIN_SIZE])\n",
    "    SAMPLE_INDEX[i] = SAMPLE_INDEX[i][:MIN_SIZE]\n",
    "CLS_ENTROPY = torch.stack(CLS_ENTROPY)\n",
    "# print(f\"[INFO] '{flags.save_dir}/cls_entropy.pkl' tensor size: {CLS_ENTROPY.size()}\")\n",
    "\n",
    "# # Savae the result \n",
    "# with open(f'{flags.save_dir}/cls_entropy.pkl', 'wb') as f:\n",
    "#     print(f\"[INFO] saved '{flags.save_dir}/cls_entropy.pkl'\")\n",
    "#     pickle.dump(CLS_ENTROPY, f)\n",
    "    \n",
    "# with open(f'{flags.save_dir}/sample_index.pkl', 'wb') as f:\n",
    "#     print(f\"[INFO] saved '{flags.save_dir}/sample_index.pkl'\")\n",
    "#     pickle.dump(SAMPLE_INDEX, f)\n",
    "# OmegaConf.save(flags, f'{flags.save_dir}/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_dataset.__getitem__(0)\n",
    "len(a)\n",
    "\n",
    "a1 = a[0]\n",
    "b2 = a[1]\n",
    "# c3= a[2]\n",
    "# # len(a)\n",
    "# print(max(a))\n",
    "# print(sum(a))\n",
    "# # print(min(a))\n",
    "\n",
    "# print(a.type())\n",
    "# # print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mimshow(a1\u001b[39m.\u001b[39msqueeze(), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mimshow(b2\u001b[39m.\u001b[39;49msqueeze(), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'squeeze'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(a1.squeeze(), cmap=\"gray\")\n",
    "plt.figure()\n",
    "plt.imshow(b2.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "torch.Size([784])\n",
      "tensor(1.0000)\n",
      "tensor(107.9412)\n"
     ]
    }
   ],
   "source": [
    "digit_image = a\n",
    "digit_image = digit_image.reshape((1, 1, 28, 28))\n",
    "print(digit_image.size())\n",
    "\n",
    "assert digit_image.size() == (1, 1, 28,28)\n",
    "digit_image = digit_image.flatten()\n",
    "print(digit_image.size())\n",
    "\n",
    "digit_image = digit_image / digit_image.sum() #[Role]:???\n",
    "print(sum(digit_image))\n",
    "print(sum(a.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[39m.\u001b[39;49msize\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "a.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy111(digit_image):\n",
    "    # assert digit_image.size() == (1, 1, 28,28)\n",
    "    digit_image = digit_image.flatten()\n",
    "    digit_image = digit_image / digit_image.sum() #[Role]:???\n",
    "    assert abs(digit_image.sum() - 1.0) < 1e-5, digit_image.sum() #[Role]:???\n",
    "    print(digit_image.log())\n",
    "    print(torch.nan_to_num(digit_image.log()))\n",
    "    entropy =  (- digit_image * torch.nan_to_num(digit_image.log())).sum() # \\sum - p log p \n",
    "    print(entropy)\n",
    "    # assert entropy >=0\n",
    "    return entropy \n",
    "\n",
    "def compute_entropy222(digit_image):\n",
    "    # assert digit_image.size() == (1, 1, 28,28)\n",
    "    digit_image = digit_image.flatten()\n",
    "    # digit_image = digit_image / digit_image.sum() #[Role]:???\n",
    "    # assert abs(digit_image.sum() - 1.0) < 1e-5, digit_image.sum() #[Role]:???\n",
    "    print(digit_image.log())\n",
    "    print(torch.nan_to_num(digit_image.log()))\n",
    "    entropy =  (- digit_image * torch.nan_to_num(digit_image.log())).sum() # \\sum - p log p \n",
    "    print(entropy)\n",
    "    # assert entropy >=0\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "        -4.4427, -2.6509, -2.6509, -2.6509, -0.7050, -0.6286, -0.3765, -2.2832,\n",
      "        -0.4293,  0.0000, -0.0319, -0.6971,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "        -2.1401, -1.9577, -0.9980, -0.5043, -0.4055, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.1252, -0.3938, -0.0079, -0.0523, -0.2683, -1.3824,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf, -1.6494, -0.0690, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0158, -1.0087, -1.1345,\n",
      "        -1.1345, -1.5159, -1.8777,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6509,\n",
      "        -0.1522, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.2530, -0.3373,\n",
      "        -0.0319, -0.0565,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf, -1.1592, -0.4914, -0.8684, -0.0079,\n",
      "        -0.0079, -0.2183, -3.1434,    -inf, -1.7801, -0.5043,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf, -2.9022, -5.5413, -0.5043, -0.0079, -1.0415,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -0.6068,\n",
      "        -0.0079, -0.2942, -4.8481,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf, -3.1434, -0.2942, -0.0079, -1.2928,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "        -1.9859, -0.0565, -0.1252, -0.4661, -0.8591, -5.5413,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf, -1.1468, -0.0606, -0.0079,\n",
      "        -0.0079, -0.7621, -2.3224,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf, -1.7346, -0.3155, -0.0079, -0.0079, -0.5306, -2.2454,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.7687,\n",
      "        -1.0087, -0.0118, -0.0079, -0.3102,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf, -0.0238, -0.0079, -0.0238,\n",
      "        -1.3824,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7126, -0.6737,\n",
      "        -0.3318, -0.0079, -0.0079, -0.2085, -4.8481,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "        -1.8777, -0.5441, -0.1075, -0.0079, -0.0079, -0.0079, -0.0198, -0.3373,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf, -2.3632, -0.8051, -0.1431, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.2380, -1.1846,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf, -2.4058, -1.3516, -0.1800, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.2530, -1.1468, -4.8481,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6509, -0.3996,\n",
      "        -0.1522, -0.0079, -0.0079, -0.0079, -0.0079, -0.2683, -1.1592, -3.3440,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "        -1.5339, -0.3938, -0.1207, -0.0079, -0.0079, -0.0079, -0.0079, -0.0441,\n",
      "        -0.6509, -3.1434,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf, -0.6286, -0.0079, -0.0079, -0.0079,\n",
      "        -0.1847, -0.6360, -0.6585, -2.7687,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
      "           -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf])\n",
      "tensor([-3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -4.4427e+00, -2.6509e+00, -2.6509e+00,\n",
      "        -2.6509e+00, -7.0498e-01, -6.2861e-01, -3.7648e-01, -2.2832e+00,\n",
      "        -4.2928e-01,  0.0000e+00, -3.1875e-02, -6.9708e-01, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -2.1401e+00, -1.9577e+00, -9.9797e-01, -5.0431e-01,\n",
      "        -4.0547e-01, -7.8741e-03, -7.8741e-03, -7.8741e-03, -7.8741e-03,\n",
      "        -7.8741e-03, -1.2516e-01, -3.9377e-01, -7.8741e-03, -5.2326e-02,\n",
      "        -2.6826e-01, -1.3824e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -1.6494e+00, -6.8993e-02,\n",
      "        -7.8741e-03, -7.8741e-03, -7.8741e-03, -7.8741e-03, -7.8741e-03,\n",
      "        -7.8741e-03, -7.8741e-03, -7.8741e-03, -1.5811e-02, -1.0087e+00,\n",
      "        -1.1345e+00, -1.1345e+00, -1.5159e+00, -1.8777e+00, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -2.6509e+00, -1.5219e-01, -7.8741e-03, -7.8741e-03,\n",
      "        -7.8741e-03, -7.8741e-03, -7.8741e-03, -2.5300e-01, -3.3726e-01,\n",
      "        -3.1875e-02, -5.6467e-02, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -1.1592e+00, -4.9141e-01, -8.6843e-01, -7.8741e-03, -7.8741e-03,\n",
      "        -2.1825e-01, -3.1434e+00, -3.4028e+38, -1.7801e+00, -5.0431e-01,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -2.9022e+00,\n",
      "        -5.5413e+00, -5.0431e-01, -7.8741e-03, -1.0415e+00, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -6.0679e-01,\n",
      "        -7.8741e-03, -2.9424e-01, -4.8481e+00, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.1434e+00, -2.9424e-01, -7.8741e-03,\n",
      "        -1.2928e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -1.9859e+00, -5.6467e-02, -1.2516e-01, -4.6609e-01,\n",
      "        -8.5913e-01, -5.5413e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -1.1468e+00, -6.0625e-02, -7.8741e-03, -7.8741e-03, -7.6214e-01,\n",
      "        -2.3224e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -1.7346e+00,\n",
      "        -3.1552e-01, -7.8741e-03, -7.8741e-03, -5.3063e-01, -2.2454e+00,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -2.7687e+00, -1.0087e+00,\n",
      "        -1.1834e-02, -7.8741e-03, -3.1015e-01, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -2.3811e-02, -7.8741e-03,\n",
      "        -2.3811e-02, -1.3824e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -1.7126e+00, -6.7373e-01,\n",
      "        -3.3178e-01, -7.8741e-03, -7.8741e-03, -2.0854e-01, -4.8481e+00,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -1.8777e+00,\n",
      "        -5.4405e-01, -1.0754e-01, -7.8741e-03, -7.8741e-03, -7.8741e-03,\n",
      "        -1.9803e-02, -3.3726e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -2.3632e+00, -8.0507e-01, -1.4310e-01, -7.8741e-03, -7.8741e-03,\n",
      "        -7.8741e-03, -7.8741e-03, -2.3796e-01, -1.1846e+00, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -2.4058e+00, -1.3516e+00, -1.7997e-01, -7.8741e-03,\n",
      "        -7.8741e-03, -7.8741e-03, -7.8741e-03, -2.5300e-01, -1.1468e+00,\n",
      "        -4.8481e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -2.6509e+00, -3.9960e-01, -1.5219e-01,\n",
      "        -7.8741e-03, -7.8741e-03, -7.8741e-03, -7.8741e-03, -2.6826e-01,\n",
      "        -1.1592e+00, -3.3440e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -1.5339e+00, -3.9377e-01,\n",
      "        -1.2073e-01, -7.8741e-03, -7.8741e-03, -7.8741e-03, -7.8741e-03,\n",
      "        -4.4095e-02, -6.5091e-01, -3.1434e+00, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -6.2861e-01, -7.8741e-03, -7.8741e-03, -7.8741e-03,\n",
      "        -1.8468e-01, -6.3599e-01, -6.5846e-01, -2.7687e+00, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "        -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38])\n",
      "tensor(25.2081)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(25.2081)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = a[0]\n",
    "a2 = a[0]\n",
    "\n",
    "# compute_entropy111(a1)\n",
    "compute_entropy222(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b036c47a88b6801bd1214d95b23982f260fad58004fa31cc4ee261405de95658"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
